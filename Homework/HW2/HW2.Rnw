\documentclass[12pt]{article}

 %% LaTeX margin settings:
\setlength{\textwidth}{7.5in}
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{-.7in}
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-2.0cm}

\newcommand{\0}{\mbox{\boldmath $0$}}
\newcommand{\D}{\mbox{\boldmath $D$}}
\newcommand{\I}{\mbox{\boldmath $I$}}
\newcommand{\m}{\mbox{\boldmath $\mu$}}
\newcommand{\R}{\mbox{\boldmath $R$}}
\newcommand{\X}{\mbox{\boldmath $X$}}
\newcommand{\V}{\mbox{\boldmath $V$}}
\newcommand{\z}{\mbox{\boldmath $z$}}
\newcommand{\Sig}{\mbox{\boldmath $\Sigma$}}

\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
opts_chunk$set(fig.width=5, fig.height=4, out.width='\\linewidth', dev='pdf', concordance=TRUE, size = 'footnotesize')
options(replace.assign=TRUE,width=82, digits = 3, max.print="72",
        show.signif.stars = FALSE)
@
%% replace = with <-
%% R output can go to112 characters per line before wrapping
%% print 3 significant digits
%% If I ask to see a big matrix or something, only show 72 lines

\large
\begin{center}
{\Large \bf  Stat 505 Assignment 2 \vspace{.2in}} \\
Leslie Gains-Germain
\end{center}

Due: Sept 12, 2014 

\begin{enumerate}


\item  Construct a 4 by 4 variance-covariance matrices showing {\bf R, D},
  and {\bf V} for each case:
  \begin{enumerate}
    \item  so that covariances are all zeroes, variances are 1, 4, 9,
      16.
      $$ \D = \left[
        \begin{array}[c]{rrrr}
          1 & 0 & 0 & 0 \\
          0 & 2 & 0 & 0 \\
          0 & 0 & 3 & 0 \\
          0 & 0 & 0 & 4
        \end{array}\right] \ \ 
         \R = \left[
        \begin{array}[c]{rrrr}
          1 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 \\
          0 & 0 & 1 & 0 \\
          0 & 0 & 0 & 1 
        \end{array}\right] \ \ 
 \V = \left[
        \begin{array}[c]{rrrr}
          1 & 0 &0 & 0\\
          0 & 4 &0 & 0\\
          0 & 0 & 9 & 0 \\
          0 & 0 & 0 &16 
        \end{array}\right] $$
    \item  so that each variance is .25 and all correlations are .6.
      $$ \D = \left[
        \begin{array}[c]{rrrr}
          .5 & 0&0 &0 \\
          0 & .5 &0 &0 \\
          0 &0 & .5 &0 \\
          0 &0 &0 & .5
        \end{array}\right] \ \ 
         \R = \left[
        \begin{array}[c]{rrrr}
          1 & 0.6 & 0.6 & 0.6 \\
          0.6 & 1 & 0.6 & 0.6 \\
          0.6 & 0.6 & 1 & 0.6 \\
          0.6 & 0.6 & 0.6 & 1  
        \end{array}\right] \ \ 
 \V = \left[
        \begin{array}[c]{rrrr}
          .25 & 0.15 & 0.15 & 0.15 \\
          0.15 & .25 & 0.15 & 0.15 \\
          0.15 & 0.15 & .25 & 0.15 \\
          0.15 & 0.15 & 0.15 & .25 
        \end{array}\right] $$
    \item so that each variance is 9, neighboring observations have
      covariance 3, observations 2 steps apart have covariance 1, and
      the covariance between observations 1 and 4 is $\frac {1}{3}$.
      
      $$ \D = \left[
        \begin{array}[c]{rrrr}
          3 & 0&0 &0 \\
          0 & 3 &0 &0 \\
          0 &0 & 3 &0 \\
          0 &0 &0 & 3
        \end{array}\right] \ \ 
         \R = \left[
        \begin{array}[c]{rrrr}
          1 & 1/3 & .111 & 0.037 \\
          1/3 & 1 & 1/3 & 0.111 \\
          0.111 & 1/3 & 1 & 1/3 \\
          0.037 & 0.111 & 1/3 & 1  
        \end{array}\right] \\
 \V = \left[
        \begin{array}[c]{rrrr}
          9 & 3 & 1 & \frac{1}{3} \\
          3 & 9 & 3 & 1 \\
          1 & 3 & 9 & 3 \\
          \frac{1}{3} & 1 & 3 & 9 
        \end{array}\right] $$
      
      
    \item  so that correlations are the same as in (c), but variances
      are $\mu_i^{1.4}$ where the vector of means is 
      $\m  = (2, 3, 7, 6)^T$.
      
<<matrix1,echo=FALSE>>=
a <- c(sqrt(2^1.4),0,0,0)
b <- c(0,sqrt(3^1.4),0,0)
c <- c(0,0,sqrt(7^1.4),0)
d <- c(0,0,0,sqrt(6^1.4))

di <- rbind(a,b,c,d)

e <- c(1,1/3,1/9,1/27)
f <- c(1/3,1,1/3,1/9)
g <- c(1/9, 1/3,1,1/3)
h <- c(1/27, 1/9, 1/3, 1)

r <- rbind(e,f,g,h)

v <- di%*%r%*%di
@

      
       $$ \D = \left[
        \begin{array}[c]{rrrr}
          \sqrt{2^{1/4}} & 0 &0 &0 \\
          0 & \sqrt{3^{1/4}} &0 &0 \\
          0 &0 & \sqrt{7^{1/4}} &0 \\
          0 &0 &0 & \sqrt{6^{1/4}}
        \end{array}\right] \ \ 
         \R = \left[
        \begin{array}[c]{rrrr}
          1 & 1/3 & .111 & 0.037 \\
          1/3 & 1 & 1/3 & 0.111 \\
          0.111 & 1/3 & 1 & 1/3 \\
          0.037 & 0.111 & 1/3 & 1  
        \end{array}\right] \\ $$ \\
 $$\V = \left[
        \begin{array}[c]{rrrr}
          2^{1.4} & 1.17 & .705 & 0.211 \\
          1.17 & 3^{1.4} & 2.81 & 0.840 \\
          .705 & 2.81 & 7^{1.4} & 4.56 \\
          .211 & .840 & 4.56 & 6^{1.4} 
        \end{array}\right] $$
  \end{enumerate}
    

\item  Let $\z \sim N_8(\0,4\I_8)$ be a random vector and
  let $\Sig$ be a 4 by 8 matrix with these entries:
\begin{verbatim}
1 1 0 0 1 0 0 0
0 1 1 0 1 1 0 0
0 0 1 1 0 1 1 0
1 0 0 1 0 0 1 1
\end{verbatim}
   Describe the distribution of $${\bf x}=\left[
    \begin{array}[c]{r}
       1\\   3\\  2\\  7
     \end{array}\right]  + \Sig\z$$ 
     
{\it {\bf x} follows a normal distribution with mean $$\left[
     \begin{array}[c]{r}
       1\\   3\\  2\\  7
     \end{array}\right]$$ with the following variance-covariance matrix $\Sigma*4I_{8}*\Sigma^{T} = $
     \begin{verbatim}
12 8 0 4
8 16 8 0
0 8 16 8
4 0 8 16
\end{verbatim}}

{\it The variances,  $\sigma^2_{x_1}, \sigma^2_{x_2}, \sigma^2_{x_3}$, and $\sigma^2_{x_4}$ are on the diagonal. Neighboring observations in ${\bf x}$ have covariance $8$, observations two steps apart have covariance $0$, and the covariance between observations $1$ and $4$ is $4$.}
   \newpage

  \item Fill in the blanks. You can use the verbatim environment
\begin{verbatim}
Source          df      SS      MS      F   p-value
--------------------------------------------------

Between groups  3   20.42     6.8067   2.409   0.068

Within groups  217  613.14    2.8255
--------------------------------------------------
Total          220  633.56
\end{verbatim}
   % or build a  \LaTeX\ table by hand with columns separated by \& signs:\\
    %\begin{tabular}[c]{lrrrrr}
%Source    &      df    &  SS   &   MS  &    F &  p-value  \\ \hline
%Between groups &       & 20.42  &      &      &   \\
%Within groups  &  217  &        &      & \\ \hline
%Total          &  220 & 633.56
 %   \end{tabular}\\
  %  or make R create the table for you.
<<anova3, results='asis', echo=F, eval = FALSE>>=
  require(xtable, quietly = TRUE)
  dfTrt <- NA
  dfE <-  NA
  SSTrt <-  NA
  MSTrt <-  NA
  SSE <-  NA
  MSE <-  NA
  Fstat <-  NA
 output <- rbind(c(dfTrt,SSTrt,MSTrt,Fstat, 1-pf( Fstat , df1 <- NA,df2<- NA)),
                 c(dfE,SSE,MSE,NA,NA),
                 c(220, 633.46,NA,NA,NA))
  dimnames(output) <- list(c("Between","Within","Total"),
                           c("df","SS","MS","F","p-value"))
xtable(output, digits = c(0,0,2,2,2,4) )
@ 

 \item 
  Set up the ANOVA model $y_{ij} = \mu +\tau_i + \epsilon{ij},\  i = 1,...4, j = 1,2$ in R  with these data:
<<fits4, eval = FALSE>>=
y <- c(3, 4, 1, 0, 7, 9, 6, 5)
#f <- factor(rep(LETTERS[1:4], each = 2))
  ## or use the gl function:
f <- gl(4,2, labels= LETTERS[1:4])
Xf <- model.matrix( y ~ f)
X <-  cbind(1,model.matrix(y ~ f + 0))
@ 



  \begin{enumerate}
  \item   Fit using \verb|lm(y ~ f)|. Give estimates of all
       cell means, explaining how they relate to the output.
       
<<fit1, echo=FALSE, results='asis', message=FALSE>>=
y <- c(3, 4, 1, 0, 7, 9, 6, 5)
#f <- factor(rep(LETTERS[1:4], each = 2))
  ## or use the gl function:
f <- gl(4,2, labels= LETTERS[1:4])
require(xtable)
lm.fit <- lm(y~f)
xtable(summary(lm.fit))
@
       
{\it The mean of $y$ in group $A$ is estimated to be $3.5$. This is given as ``intercept'' in the output above. The mean of $y$ in group $B$ is estimated to be $3.5-3.0=0.5$. The mean of $y$ in group $C$ is estimated to be $3.5+4.5=8$. The mean of $y$ in group $D$ is estimated to be $3.5+2=5.5$.}
    \item Do the same using  \verb|lm( y ~ f + 0)|.
    
{\it The output below gives the estimates of the cell means for each group. }
    
<<fits5, echo=FALSE, results='asis', message=FALSE>>=
y <- c(3, 4, 1, 0, 7, 9, 6, 5)
f <- factor(rep(LETTERS[1:4], each = 2))
## or use the gl function:
lm.fit5 <- lm(y~f + 0)
require(xtable)
print(xtable(summary(lm.fit5)))
#anova(lm.fit1)
@ 

\newpage

    \item  Is $X_f^T X_f$ nonsingular (invertible)?  If so, solve the
      normal  equations based on $X_f$ using \verb|crossprod|  and
      \verb|solve| functions.  If not, find a solution using the Moore
      -- Penrose generalized inverse.
      
{\it Yes, $X_f^T X_f$ is nonsingular because $X_f$ is built under the constraint that $\tau_{1}=0$. I found the least squares solution using crossprod and solve and I got the same output as the reference coded model in (a).}
      
      
 <<solve, echo=FALSE>>=
xf <- model.matrix( y ~ f)
det <- crossprod(xf)
solve(det)%*%t(xf)%*%y
y <- c(3, 4, 1, 0, 7, 9, 6, 5)
@     
      
    \item Repeat (a)  using  \verb| lm(y ~ X + 0, singular.ok=T)|.
    
{\it We can see from the output below that group D is the reference level. The estimate for the mean of group A is $5.5-2=3.5$. The estimate for the mean of group B is $5.5-5=0.5$, and the estimate for the mean of group C is $5.5+2.5=8$. }


 <<solve2, echo=FALSE, results='asis'>>=
x <-  cbind(1,model.matrix(y ~ f + 0))
lm.sing <- lm(y~x+0, singular.ok=T)
require(xtable)
xtable(summary(lm.sing))
@   

   \item Use the Moore Penrose inverse to find another solution to
     the  normal equations for the full $\X$ matrix.  Show that
     $\widehat{\mu}$ and $\widehat{\tau}_i$ differ from those above,
     but estimates  of the cell means are the same. 
     
<<solve3, echo=FALSE, message=FALSE>>=
det1 <- crossprod(x)
require(MASS)
inverse <- ginv(det1)
zapsmall(inverse%*%t(x)%*%y)
@  

{\it We see that $\widehat{\mu}=3.5$, $\widehat{\tau_{A}}=0$, $\widehat{\tau_{B}}=-3.0$, $\widehat{\tau_{C}}=4.5$, and $\widehat{\tau_{D}}=2.0$. $\tau_{D}$ was set to $0$ in part (d), but here $\tau_{A}$ is set to zero. As a result, we get different estimates for $\mu$, $\tau_A$, $\tau_B$, $\tau_C$, and $\tau_D$, but the estimated cell means ($\widehat{\mu+\tau_{i}}$) are the same ($3.5, 0.5, 8.0$, and $5.5$ for groups A, B, C, and D).}

     
    \item Explain how \verb|Xf| and \verb|X| differ and how they are
      used to create the estimates in parts a, b, d, and e.
      
{\it The first column of X is a linear combination of the other four columns. The columns of the model matrix, $X_f$, are linearly independent because $X_f$ is simply the X matrix with the second column removed. By removing the second column of X, the computer essentially imposes the constraint $\tau_A=0$. This is what we see in parts (a) and (c).  We see in part (e) that the Moore-Penrose generalized inverse also uses the constraint $\tau_{A}=0$ to solve the normal equations for the full X matrix. In part (d), the computer uses the constraint $\tau_D=0$. Although the parameter estimates differ depending on the constraint, all methods give the same estimates for the cell means.  }

\end{enumerate}

\end{enumerate}

\begin{center}
  {\large\bf R Code}
\end{center}


<<matrix1, eval=FALSE>>=
@

<<fits4, eval = FALSE>>=
@ 

<<fit1, eval=FALSE>>=
@

<<fits5, eval=FALSE>>=
@

<<solve, eval=FALSE>>=
@

<<solve2, eval=FALSE>>=
@

<<solve3, eval=FALSE>>=
@





  \end{document}